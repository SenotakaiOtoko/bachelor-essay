\section{Программная реализация прототипа приложения}

\subsection{Классификация изображений}

Для задач классификации изображений наилучшие результаты показывает Convolutional Neural Network или сверточная нейронная сеть, которая является логическим развитием идей таких архитектур нейронных сетей как когнитрона и неокогнитрона. 
Успех обусловлен возможностью учета двумерной связности изображения, в отличие от многослойного персептрона \cite{conv-neoro}. 

Сверточные нейронные сети обеспечивают частичную устойчивость к изменениям масштаба, смещениям, поворотам, смене ракурса и прочим искажениям. 
Сверточные нейронные сети объединяют три архитектурных идеи, для обеспечения инвариантности к изменению масштаба, повороту сдвигу и пространственным искажениям:
\begin{itemize}
    \item локальные рецепторные поля (обеспечивают локальную двумерную связность нейронов);
    \item общие синаптические коэффициенты (обеспечивают детектирование некоторых черт в любом месте изображения и уменьшают общее число весовых коэффициентов);
    \item иерархическая организация с пространственными подвыборками.
\end{itemize}

На данный момент сверточная нейронная сеть и ее модификации считаются лучшими по точности и скорости алгоритмами нахождения объектов на сцене. 
Начиная с 2012 года, сверточные нейронные сети занимают первые места на известном международном конкурсе по распознаванию образов ImageNet.

Именно поэтому принято решение о дальнейшем использовании сверточных нейронных сетей. 
Наиболее интересными представителями класса сверточных нейронных сетей являются сети «GoogleNet», «InceptionV3» и «VGG16».

VGG16 — модель сверточной нейронной сети, предложенная K. Simonyan и A. Zisserman из Оксфордского университета \cite{vgg16alg}. 
Модель достигает точности 92.7\% — топ-5, при тестировании на подмножестве данных ILSVRC-2014 (ImageNet Large Scale Visual Recognition Challenge — Кампания по широкомасштабному распознаванию образов в ImageNet) множества ImageNet в задаче распознавания объектов на изображении. 

Топ 5 — метрика, в которой алгоритм может выдать 5 вариантов класса картинки. Ошибка засчитывается, если среди всех этих вариантов нет правильного. В тестовом наборе данных 150 тысяч картинок и 1000 категорий, то есть задача крайне нетривиальна.

Это одна из самых известных моделей сверточной нейронной сети, которая была отправлена на соревнование ILSVRC-2014. Она является улучшенной версией нейронной сети AlexNet, которая была первой сверточной нейронной сетью, победившей в ILSVRC\cite{imagenet-challenge}. Структура нейронной сети AlexNet представлена на рисунке \ref{alexnet-structure}

\addimghere{alexnet-structure}{0.8}{Структура нейронной сети AlexNet}{alexnet-structure}

В VGG16 (рисунок \ref{vgg-structure}) по сравнению с сетью AlexNet были заменены большие фильтры (размера 11 и 5 в первом и втором сверточном слое, соответственно) на несколько фильтров размера 3х3, следующих один за другим. Сеть VGG16 для конкурса обучалась на протяжении нескольких недель при использовании видеокарт NVIDIA TITAN BLACK. 

\addimghere{vgg-structure}{0.8}{Структура нейронной сети VGG16}{vgg-structure}

GoogLeNet (рисунок \ref{googlenet-structure}) – сверточная нейронная сеть, спроектированная компанией Google и выигравшая ILSVRC-2014 с результатом точности 93,33\% топ 5 \cite{imagenet-challenge}.
Сеть AlexNet, победившая в 2012 году не помещалась в память одного графического ускорителя, объем памяти которого составлял 3GB. 
Одной из главных идей GoogLeNet была эффективность вычислений при небольшом размере модели и небольшом количестве самих вычислений, например, чтобы можно было использовать нейронную сеть на носимых устройствах.

\addimghere{googlenet-structure}{1}{Структура нейронной сети GoogLeNet}{googlenet-structure}

При проектировании сети GoogLeNet также учитывались недостатки нейронной сети AlexNet. 

В структуре AlexNet производились большие свертки, которые требуют много параметров, в GoogLeNet свертки стали меньше, однако увеличилось количество слоев в свертках.

После чего было произведено сильное уменьшение количества измерений, чтобы компенсировать более толстые слои. 
Данная операция производилась с помощью слоя, выполняющего роль линейного фильтра (рисунок \ref{inception-block}), примененного по всему изображению, чтобы линейно смешать текущее количество измерений в меньшее.

На каждом из уровней использовалось одновременно несколько подобных фильтров разного размера. 
Это делалось для того, чтобы улавливать градиентные участки изображения разного масштаба.

\addimghere{inception-block}{0.35}{Структура блока inception сети GoogLeNet}{inception-block}

В GoogLeNet отсутствуют полносвязные слои, так как в них слишком много параметров. 
Вместо этого на последнем уровне выполняется операция субдескритезации, после которой информация подается непосредственно на выходной слой.

Данные манипуляции позволили примерно в 10 раз сократить количество параметров нейронной сети по сравнению в AlexNet, как следствие и количество вычислений, производимых при обучении и непосредственной работе нейронной сети.

InceptionV3 – дальнейшее развитие идеи эффективных сверточных нейронных сетей от Google. Данная нейронная сеть достигает точности 92,8\% топ 5 на ILSVRC-2015 \cite{imagenet-challenge}. Структура нейронной сети InceptionV3 представлена на рисунке \ref{inception-structure}
 
\addimghere{inception-structure}{0.8}{Структура нейронной сети InceptionV3}{inception-structure}

При проектировании InceptionV3, в отличие от первой версии, были сформулированы основные принципы построения архитектуры:
\begin{itemize}
    \item Большое количество сигналов расположены в непосредственной близости друг от друга. Это можно использовать, чтобы делать свертки меньшего размера. Соседние сигналы часто коррелируют, а значит, можно уменьшить размерность перед сверткой без потери информации;
    \item при увеличении свободного количества ресурсов для их эффективного использования, необходимо увеличивать и глубину и ширину сети одновременно;
    \item неэффективно использовать слои, резко уменьшающие количество параметров, особенно в начале нейронной сети;
    \item «широкие» слои быстрее обучаются, что особенно важно на высоких уровнях (но локально, т.е. можно после них уменьшать размерность).
\end{itemize}

Структура блоков сети также претерпела некоторые изменения. (рисунок \ref{inception3-block})
Была произведена декомпозиция слоя с фильтром NxN на два слоя с последовательными фильтрами 1xN и Nx1.

\addimghere{inception3-block}{0.35}{Структура блока inception нейронной сети InceptionV3}{inception3-block}

В качестве структуры нейронной сети для дальнейшей работы выбрана InceptionV3, так как она показывает наилучшие результаты по сравнению с другими вышеназванными сверточными нейронными сетями, а также имеет один из лучших показателей эффективности.

\subsection{Подготовка данных для обучения нейронной сети}
При подготовке исходных данных сформулированы следующие требования к итоговому набору данных:
\begin{itemize}
  \item большое количество классифицированных изображений (не менее 50 тысяч);
  \item состоятельность исходных данных в области применения разрабатываемого программного средства;
  \item не менее 1000 итоговых классов изображений.
\end{itemize}

Для формирования набора данных для обучения была выбрана крупнейшая на данный момент база классифицированных изображений – ImageNet. 
База насчитывает более 14 млн изображений, разбитых на 21 тыс категорий. 
ImageNet использует вариант семантической сети WordNet для категоризации объектов, которая достаточно детализирована, например, породы собак представлены 120 классами.

Для формирования набора классов, используем теги популярной социальной сети-фотохостинга – Instagram. 
Если отобрать некоторое количество популярных тегов, предварительно отсортировав их по частоте использования и отсеяв теги, не относящиеся к классификации изображений, то с высокой долей вероятности получим набор тегов, отображающих реальные интересы пользователей социальной сети, связанных с производством медиаконтента.

Так, как Instagram не предоставляет официальной статистики по совокупности тегов, а только информацию о количестве публикаций к конкретному тегу, было разработано программное обеспечение, решающее задачу сбора статистики по популярным тегам.

Так, как к публикациям в Instagram можно указывать до 30 тегов, чем в свою очередь активно пользуются в социальной сети, можно собрать с высокой долей вероятности достоверную информацию о статистике тегов, построив график зависимости тегов через публикации. 
Однако, так как на момент выполнения работы количество публикаций только по одному тегу «love» превышало 1,5 млрд \cite{love}, построение полного графика потребовало бы колоссального количества вычислительных ресурсов. Кроме того, полный анализ не требовался для получения сравнительно небольшого количества популярных тегов.

Для составления относительно состоятельного рейтинга популярных тегов произведена многократная выборка тегов через связь тег-публикации-теги с помощью api Instagram по поиску популярных публикаций по тегу. 
Из совокупности выборок составлена и проранжирована база популярных тегов.

\addimghere{instagram-ranged}{0.8}

Составив рейтинг из достаточно большого количества тегов, для отбора тегов, относящихся непосредственно к классификации изображений, получено множество на пересечении множества тегов с множеством слов из краткого словесного описания категорий объектов из сети WordNet. 

\addimghere{wordnet-ranged}{0.8}

В дополнение проранжировано полученное множество категорий по популярности, отсеяны категории, содержащие менее 500 изображений в базе ImageNet для улучшения качества обучающей выборки, и выбраны 1000 наиболее популярных категорий. 
Получен необходимый набор категорий для обучения нейронной сети. 
Список адресов изображений получен с помощью api ImageNet по адресу http://www.image-net.org/api/text/imagenet.synset.geturls?wnid=n00015388, где n00015388 - наименование одной из категорий изображений, представленных в базе изображений ImageNet.

Исходя из вышеизложенного алгоритма подготовки данных, написано программное решение на языке программирования python для подготовки данных для обучения нейронной сети. Программный код приведен в приложении.

Подготовка исходных данных обучающей выборки при помощи написанного программного решения заняла двое суток без учета времени скачивания изображений. 
Количество изображений в обучающей выборке составило более 1 млн. 
Общий объем базы изображений обучающей выборки превысил 500 ГБ.

\subsection{Обучение нейронной сети}

Так, как выбранная нейронная сеть InceptionV3 является сверточной нейронной сетью, требовательной к ресурсам при обучении, обучить с нуля в разумные сроки без привлечения колоссальных вычислительных ресурсов не представлялось возможным.

Была использована модель, заранее обученная на большом количестве изображений из базы ImageNet. 
Такой моделью на момент выполнениия работы располагал Keras — открытая библиотека для построения и работы нейронных сетей, написанная на языке Python. 
Распознаваемые классы обученной нейронной сети с некоторой вероятностью могут пресекаться с распознаваемыми классами, используемыми в программном решении, в которое планируется встраивать нейронную сеть. 
Также у большинства классов данной базы изображений идентичный или сильно похожий набор признаков, по которым нейронная сеть делает предположение о принадлежности распознаваемого объекта к тому или иному классу. 
Это дало преимущество при дообучении заранее обученной сети распознаванию новых классов.

Модель обучена по частям. 
Сначала проведена аугментация изображений и их последующий процессинг нижней частью сети (блоком Inception). 
Полученный результат сохранен. 
С его помощью обучен верхний слой. 
Объединены верхний и нижний слои модели, заблокированы от обучения все слои Inception, кроме последнего. 
Данный метод обучения носит название «transfer learning» \cite{transfer-learning}.

Для обучения нейронной сети в разумные сроки использованы вычислительные мощности Google, а именно Google Cloud ML. 
На момент выполнения работы, при первой авторизации ресурс предлагал бесплатно воспользоваться частью вычислительных мощностей, которую можно было купить за 300\$. 
Бесплатного доступа хватило бы примерно на 10 часов работы вычислительного устройства с одним графическим ускорителем NVIDIA TESLA V100 (самый технически оснащенный графический ускоритель, по производительности сопоставимый с 100 CPU), шестнадцатью виртуальных CPU и 52 ГБ оперативной памяти.

Для инициализации CloudShell была выполнена следующая команда в терминальном интерфейсе сервиса:
\begin{lstlisting}
  curl https://raw.githubusercontent.com/GoogleCloudPlatform/cloudml-samples/master/tools/setup_cloud_shell.sh | bash
\end{lstlisting}

Результатом работы данной команды являются набор необходимых пакетов для работы с нейронными сетями в CloudShell. 
После выполнения команды обновлена переменная PATH и инициализирован модуль Machine Learning с текущим проектом:
\begin{lstlisting}
  export PATH=${HOME}/.local/bin:${PATH}
  gcloud beta ml init-project | y
\end{lstlisting}

После подготовки данных для обучения, создан контейнер для обучения:
\begin{lstlisting}
  PROJECT_NAME=inceptionV3training
  TRAIN_BUCKET=gs://${PROJECT_NAME}
  gsutil mb ${TRAIN_BUCKET}
\end{lstlisting}


После создания контейнера, загружены тренировочные и тестовые данные в контейнер:
\begin{lstlisting}
  ~/src/inc $ gsutil cp test.* ${TRAIN_BUCKET}/input
  ~/src/inc $ gsutil cp train.* ${TRAIN_BUCKET}/input
\end{lstlisting}

После выполнения данных команд, проведено непосредственно обучение на удаленных вычислительных мощностях Google. 
Листинг команд для запуска представлен в приложении.

Итоговое обучение нейронной сети с использованием ресурсов Google и применением графических ускорителей заняло порядка 10 часов. 
Программный код на языке python для обучения нейронной сети представлен в приложении.

\subsection{Интеграция нейронной сети в программный продукт}

Обученную модель нейронной сети можно интегрировать в программный продукт двумя способами. 
Первый и более простой – использовать нейронную сеть непосредственно из python программы, вызывая ее для задачи классификации загруженных изображений при их добавлении в базу данных или по расписанию.


Для реализации данного способа в операционных системах семейства linux и BSD необходимо создать задачу в планировщике cron. 
Для этого необходимо выполнить следующую команду в терминале
\begin{lstlisting}
  crontab -e
\end{lstlisting}
После чего внести непосредственно задачу в окне редактора в следующем формате:
\begin{lstlisting}
  1 2 3 4 5 /path/to/command arg1 arg2
\end{lstlisting}
где 1 – минута, 2 – час, 3 – день, 4 – месяц, 5 – день недели, «/path/to/command» – выполняемая команда, а arg – аргументы команды.


В случае с python программой, строка в cron будет выглядеть следующим образом:
\begin{lstlisting}
  */1 * * * * python /opt/classify-task/inceptionV3-additional-trained.py
\end{lstlisting}

Как уже упоминалось ранее, преимущество данного способа в простоте его реализации, а также независимости от основного программного приложения. 
Такую задачу можно легко масштабировать, скорректировать, изменить или отключить, не внося изменения в основное приложение.


Недостаток же данного способа вытекает напрямую из преимуществ. 
Задача классификации будет выполняться с одинаковой частотой, независимо от нагрузки на сервис и количества неклассифицированных данных в базе данных загруженных изображений.


Второй способ предполагает интеграцию непосредственно в код разрабатываемого программного продукта. 
Так, как программный продукт разрабатывается на языке программирования Java, для интеграции был выбран фреймворк для работы с нейронными сетями deeplearning4j. 
Он имеет встроенную поддержку импорта нейронных сетей, экспортированных из Keras. 
Для экспорта нейронной сети необходимо выполнить в python окружении с обученной нейронной сетью следующую команду:
\begin{lstlisting}
  model.save('incV3-add-trained.h5')
\end{lstlisting}

Затем необходимо импортировать сохраненную модель в Java окружение следующей последовательностью команд:
\begin{lstlisting}
  String inc = new ClassPathResource("incV3-add-trained.h5").getFile().getPath();
  MultiLayerNetwork model = KerasModelImport.importKerasSequentialModelAndWeights(inc);
\end{lstlisting}

После чего можно использовать обученную модель непосредственно из Java окружения. 
Преимущество данного способа в том, что можно вызвать обученную нейронную сеть для классификации не только по расписанию, но и сразу после загрузки новых фотографий. 
Однако для изменения параметров существующей сети, необходимо перезапускать приложение.


В ходе работы были реализованы последовательно оба способа интеграции нейронной сети в программное приложение. 
Был сделан выбор в пользу второго способа – с интеграцией обработки непосредственно в код приложения ввиду возможности масштабирования решения вместе с приложением и выполнения кода,  ответственного за классификацию только при необходимости.

\subsection{Выделение цветовых кластеров на изображении}

Для выделения цветовых кластеров на фотографии, при их загрузке на фотохостинг, пиксели на фотографии необходимо кластеризировать.
Так, как заранее не известно количество цветовых кластеров на фотографии, необходимо использовать адаптивный алгоритм, определяющий количество кластеров в процессе работы, также устойчивый к выбросам.
Таким алгоритмом является DBSCAN (Основанная на плотности пространственная кластеризация для приложений с шумами) \cite{dbscan-alg}.

Алгоритм DBSCAN может быть разложен на следующие шаги:
\begin{enumerate}
    \item найти точки в \(\mathcal{\varepsilon}\) окрестности каждой точки и выделить основные точки с более чем minPts соседями;
    \item найти связные компоненты основных точек на графе соседей, игнорируя все неосновные точки;
    \item назначить каждую неосновную ближайшему кластеру, если кластер является \(\mathcal{\varepsilon}\) -соседним, в противном случае считать точку шумом.
\end{enumerate}

Хорошей практикой является выбор значения minPts равному рамерности данных, увеличенной на единицу.
Величину \(\mathcal{\varepsilon}\) можно выбрать из графа k-расстояний\cite{k-graph}:
\begin{enumerate}
    \item вычислить средние расстояния по minPts ближайшим соседям для каждой точки;
    \item отсортировать полученные значения;
    \item выбрать \(\mathcal{\varepsilon}\) в точке колена получившегося графика.
\end{enumerate}

Так, как данный алгоритм в результате работы не находит центр кластера, необходимо вычислить геометрическую медиану полученных кластеров.
Выполнить данную операцию можно почти за линейное время, используя алгоритм Коэна, Ли, Миллера и Пачоки \cite{median-linear}.
В результате работы алгоритма были получены данные о цветовых характеристиках изображения.


\clearpage